{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_V8vunn919lj"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "import h5py\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import shutil\n",
        "import cv2\n",
        "import os\n",
        "from numba import jit\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXTj5gL_iWXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e146686b-732f-417c-c531-bce9729a56d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"http://people.csail.mit.edu/yalesong/tvsum/tvsum50_ver_1_1.tgz\""
      ],
      "metadata": {
        "id": "0egsHuVBRld1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGp64lHW1_Md"
      },
      "outputs": [],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.VGG19  (\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(224, 224, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.vgg19.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((224, 224, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKnheUciAqQU"
      },
      "outputs": [],
      "source": [
        "@jit(nopython=True)\n",
        "def scatters_with_numba(scatters,K1,K2,n):\n",
        "  for i in range(0,n):\n",
        "    for j in range(i,n):\n",
        "      scatters[i, j] = K1[j+1]-K1[i] - (K2[j+1, j+1]+K2[i, i]-K2[j+1,i]-K2[i,j+1])/(j-i+1)\n",
        "  \n",
        "  return scatters\n",
        "\n",
        "def calc_scatters(K):\n",
        "    \"\"\"\n",
        "    Calculate scatter matrix:\n",
        "    scatters[i,j] = {scatter of the sequence with starting frame i and ending frame j} \n",
        "    \"\"\"\n",
        "    n = K.shape[0]\n",
        "    K1 = np.cumsum([0] + list(np.diag(K)))\n",
        "    K2 = np.zeros((n+1, n+1))\n",
        "    K2[1:, 1:] = np.cumsum(np.cumsum(K, 0), 1); # TODO: use the fact that K - symmetric\n",
        "\n",
        "    scatters = np.zeros((n, n));\n",
        "    \n",
        "    scatters = scatters_with_numba(scatters,K1,K2,n)\n",
        "    return scatters\n",
        "\n",
        "@jit(nopython=True)\n",
        "def max(x,y):\n",
        "  if x > y:\n",
        "    return x\n",
        "  else :\n",
        "    return y\n",
        "\n",
        "@jit(nopython=True)\n",
        "def cpd_nonlin_with_numba(m,n,p,I, J, lmin, lmax, backtrack):\n",
        "  if backtrack == True:\n",
        "    backtrack = 1\n",
        "  else:\n",
        "    backtrack = 0\n",
        "\n",
        "  for k in range(1, m+1):\n",
        "    for l in range((k+1)*lmin, n+1):\n",
        "      I[k,l] = 1e100\n",
        "      for t in range(max(k*lmin,l-lmax),l-lmin+1):\n",
        "        c = I[k-1, t] + J[t, l-1]\n",
        "        if c < I[k][l]:\n",
        "          I[k, l] = c\n",
        "          if backtrack == 1:\n",
        "            p[k, l] = t\n",
        "\n",
        "\n",
        "  return p,I\n",
        "\n",
        "\n",
        "def cpd_nonlin(K, ncp, lmin=1, lmax=100000, backtrack=True, verbose=True,\n",
        "    out_scatters=None):\n",
        "    \"\"\" Change point detection with dynamic programming\n",
        "    K - square kernel matrix \n",
        "    ncp - number of change points to detect (ncp >= 0)\n",
        "    lmin - minimal length of a segment\n",
        "    lmax - maximal length of a segment\n",
        "    backtrack - when False - only evaluate objective scores (to save memory)\n",
        "    \n",
        "    Returns: (cps, obj)\n",
        "        cps - detected array of change points: mean is thought to be constant on [ cps[i], cps[i+1] )    \n",
        "        obj_vals - values of the objective function for 0..m changepoints\n",
        "        \n",
        "    \"\"\"   \n",
        "    m = int(ncp)  # prevent numpy.int64\n",
        "    \n",
        "    (n, n1) = K.shape\n",
        "    assert(n == n1), \"Kernel matrix awaited.\"    \n",
        "    \n",
        "    assert(n >= (m + 1)*lmin)\n",
        "    assert(n <= (m + 1)*lmax)\n",
        "    assert(lmax >= lmin >= 1)\n",
        "    \n",
        "    if verbose:\n",
        "        #print \"n =\", n\n",
        "        print (\"Precomputing scatters...\")\n",
        "    J = calc_scatters(K)\n",
        "\n",
        "    print(backtrack)\n",
        "    \n",
        "    if out_scatters != None:\n",
        "        out_scatters[0] = J\n",
        "\n",
        "    if verbose:\n",
        "        print (\"Inferring best change points...\")\n",
        "    # I[k, l] - value of the objective for k change-points and l first frames\n",
        "    I = 1e101*np.ones((m+1, n+1))\n",
        "    I[0, lmin:lmax] = J[0, lmin-1:lmax-1]\n",
        "\n",
        "    if backtrack:\n",
        "        # p[k, l] --- \"previous change\" --- best t[k] when t[k+1] equals l\n",
        "        p = np.zeros((m+1, n+1), dtype=int)\n",
        "    else:\n",
        "        p = np.zeros((1,1), dtype=int)\n",
        "            \n",
        "    p,I = cpd_nonlin_with_numba(m,n,p,I, J, lmin, lmax, backtrack)\n",
        "    \n",
        "    # Collect change points\n",
        "    cps = np.zeros(m, dtype=int)\n",
        "    \n",
        "    if backtrack:\n",
        "        cur = n\n",
        "        for k in range(m, 0, -1):\n",
        "            cps[k-1] = p[k, cur]\n",
        "            cur = cps[k-1]\n",
        "\n",
        "    scores = I[:, n].copy() \n",
        "    scores[scores > 1e99] = np.inf\n",
        "    return cps, scores\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCcnGrwoAqsE"
      },
      "outputs": [],
      "source": [
        "def cpd_auto(K, ncp, vmax, desc_rate=1, **kwargs):\n",
        "  m = ncp\n",
        "  (_, scores) = cpd_nonlin(K, m, backtrack=False, **kwargs)\n",
        "  \n",
        "  N = K.shape[0]\n",
        "  N2 = N*desc_rate  # length of the video before subsampling\n",
        "  \n",
        "  penalties = np.zeros(m+1)\n",
        "  # Prevent division by zero (in case of 0 changes)\n",
        "  ncp = np.arange(1, m+1)\n",
        "  penalties[1:] = (vmax*ncp/(2.0*N2))*(np.log(float(N2)/ncp)+1)\n",
        "  \n",
        "  costs = scores/float(N) + penalties\n",
        "  m_best = np.argmin(costs)\n",
        "  (cps, scores2) = cpd_nonlin(K, m_best, **kwargs)\n",
        "\n",
        "  return (cps, costs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRG-ORDX1_KM"
      },
      "outputs": [],
      "source": [
        "class Data_Generator:\n",
        "  \"\"\"\n",
        "  vgg19 modelini indirmeden önce frame işlemleri yaklaşık 200 saniye sürdü\n",
        "  indirdikten sonra ise yaklaşık 13 saniye sürdü\n",
        "\n",
        "  change point işlemleri : 0.0063135623931884766 saniye sürdü\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,video_path,save_path):\n",
        "    self.dataset = {}\n",
        "    self.video_list = []\n",
        "    self.video_path = \"\"\n",
        "    self.frame_root_path = '/content/drive/MyDrive/summe/frames'\n",
        "    self.h5_file = h5py.File(save_path, 'w')\n",
        "    self.set_video_list(video_path,save_path)\n",
        "\n",
        "\n",
        "  def set_video_list(self, video_path,save_path):\n",
        "    if os.path.isdir(video_path):\n",
        "      self.video_path = video_path\n",
        "      files = glob.glob(video_path+\"/*.mp4\", recursive = True)\n",
        "      self.video_list = files\n",
        "      self.video_list.sort()\n",
        "    \n",
        "    else:\n",
        "      self.video_path = \"\"\n",
        "      self.video_list.append(video_path)\n",
        "    \n",
        "    for idx, file_name in enumerate(self.video_list):\n",
        "      self.dataset[\"video_{}\".format(idx+1)] = {}\n",
        "      self.h5_file.create_group(\"video_{}\".format(idx+1))\n",
        "\n",
        "\n",
        "  def extract_feature(self, frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frame = frame[None, ...]\n",
        "    feature = feature_extractor.predict(frame)\n",
        "    frame_feature = feature.flatten()\n",
        "\n",
        "    return feature\n",
        "\n",
        "  def get_change_point(self, video_feat, n_frame, fps):\n",
        "    n = n_frame / fps\n",
        "    m = int(math.ceil(n/2.0))\n",
        "    K = np.dot(video_feat, video_feat.T)\n",
        "    change_points, _ = cpd_auto(K, m, 1)\n",
        "    change_points = np.concatenate(([0], change_points, [n_frame-1]))\n",
        "\n",
        "    temp_change_points = []\n",
        "    for idx in range(len(change_points)-1):\n",
        "        segment = [change_points[idx], change_points[idx+1]-1]\n",
        "        if idx == len(change_points)-2:\n",
        "            segment = [change_points[idx], change_points[idx+1]]\n",
        "\n",
        "        temp_change_points.append(segment)\n",
        "    change_points = np.array(list(temp_change_points))\n",
        "\n",
        "    temp_n_frame_per_seg = []\n",
        "    for change_points_idx in range(len(change_points)):\n",
        "        n_frame = change_points[change_points_idx][1] - change_points[change_points_idx][0]\n",
        "        temp_n_frame_per_seg.append(n_frame)\n",
        "    n_frame_per_seg = np.array(list(temp_n_frame_per_seg))\n",
        "\n",
        "    return change_points, n_frame_per_seg\n",
        "\n",
        "\n",
        "  def generate_ds(self):\n",
        "    for video_idx, video_filename in enumerate(tqdm(self.video_list)):\n",
        "      video_path = video_filename\n",
        "      if os.path.isdir(self.video_path):\n",
        "        video_path = os.path.join(self.video_path, video_filename)\n",
        "      video_basename = os.path.basename(video_path).split(\".\")[0]\n",
        "\n",
        "      if not os.path.exists(os.path.join(self.frame_root_path, video_basename)):\n",
        "        os.mkdir(os.path.join(self.frame_root_path, video_basename))\n",
        "\n",
        "      video_capture = cv2.VideoCapture(video_path)\n",
        "      fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "      n_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "      frame_list = []\n",
        "      picks = []\n",
        "      video_feat = None\n",
        "      video_feat_for_train = None\n",
        "\n",
        "      start_time = time.time()\n",
        "      \n",
        "      for frame_idx in range(n_frames-1):\n",
        "        success, frame = video_capture.read()\n",
        "        if success:\n",
        "            frame_feat = self.extract_feature(frame)\n",
        "\n",
        "            if frame_idx % 15 == 0:\n",
        "                picks.append(frame_idx)\n",
        "\n",
        "                if video_feat_for_train is None:\n",
        "                    video_feat_for_train = frame_feat\n",
        "                else:\n",
        "                    video_feat_for_train = np.vstack((video_feat_for_train, frame_feat))\n",
        "\n",
        "            if video_feat is None:\n",
        "                video_feat = frame_feat\n",
        "            else:\n",
        "                video_feat = np.vstack((video_feat, frame_feat))\n",
        "\n",
        "            img_filename = \"{}.jpg\".format(str(frame_idx).zfill(5))\n",
        "            cv2.imwrite(os.path.join(self.frame_root_path, video_basename, img_filename), frame)\n",
        "\n",
        "        else:\n",
        "            break\n",
        "\n",
        "      video_capture.release()\n",
        "      print(\"\\n The passing time for frames :\",time.time()-start_time)\n",
        "      \n",
        "      start_time = time.time() \n",
        "\n",
        "      change_points, n_frame_per_seg = self.get_change_point(video_feat, n_frames, fps)\n",
        "      \n",
        "      print(\"\\n The passing time for frames :\",time.time()-start_time)\n",
        "\n",
        "\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['features'] = list(video_feat_for_train)\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['picks'] = np.array(list(picks))\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['n_frames'] = n_frames\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['fps'] = fps\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['change_points'] = change_points\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['n_frame_per_seg'] = n_frame_per_seg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Yeni Data Generator\n"
      ],
      "metadata": {
        "id": "2S7nc7Y_gCej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqdOxLybuRum"
      },
      "outputs": [],
      "source": [
        "class Data_GeneratorNew:\n",
        "  \"\"\"\n",
        "  10 saniyelik video için\n",
        "\n",
        "  vgg19 modelini indirmeden önce frame işlemleri yaklaşık 200 saniye sürdü\n",
        "  indirdikten sonra ise yaklaşık 13 saniye sürdü\n",
        "  \n",
        "  değişiklerden sonra bu süre 11-12 saniyeye düştü\n",
        "\n",
        "\n",
        "  change point işlemleri : 0.0063135623931884766 saniye sürdü\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,video_path,save_path):\n",
        "    self.dataset = {}\n",
        "    self.video_list = []\n",
        "    self.video_path = \"\"\n",
        "    self.frame_root_path = '/content/drive/MyDrive/summe/frames'\n",
        "    self.h5_file = h5py.File(save_path, 'w')\n",
        "    self.set_video_list(video_path,save_path)\n",
        "\n",
        "\n",
        "  def set_video_list(self, video_path,save_path):\n",
        "    if os.path.isdir(video_path):\n",
        "      self.video_path = video_path\n",
        "      files = glob.glob(video_path+\"/*.mp4\", recursive = True)\n",
        "      self.video_list = files\n",
        "      self.video_list.sort()\n",
        "    \n",
        "    else:\n",
        "      self.video_path = \"\"\n",
        "      self.video_list.append(video_path)\n",
        "    \n",
        "    for idx, file_name in enumerate(self.video_list):\n",
        "      self.dataset[\"video_{}\".format(idx+1)] = {}\n",
        "      self.h5_file.create_group(\"video_{}\".format(idx+1))\n",
        "\n",
        "  def get_change_point(self, video_feat, n_frame, fps):\n",
        "    n = n_frame / fps\n",
        "    m = int(math.ceil(n/2.0))\n",
        "    K = np.dot(video_feat, video_feat.T)\n",
        "    change_points, _ = cpd_auto(K, m, 1)\n",
        "    change_points = np.concatenate(([0], change_points, [n_frame-1]))\n",
        "\n",
        "    temp_change_points = []\n",
        "    for idx in range(len(change_points)-1):\n",
        "        segment = [change_points[idx], change_points[idx+1]-1]\n",
        "        if idx == len(change_points)-2:\n",
        "            segment = [change_points[idx], change_points[idx+1]]\n",
        "\n",
        "        temp_change_points.append(segment)\n",
        "    change_points = np.array(list(temp_change_points))\n",
        "\n",
        "    temp_n_frame_per_seg = []\n",
        "    for change_points_idx in range(len(change_points)):\n",
        "        n_frame = change_points[change_points_idx][1] - change_points[change_points_idx][0]\n",
        "        temp_n_frame_per_seg.append(n_frame)\n",
        "    n_frame_per_seg = np.array(list(temp_n_frame_per_seg))\n",
        "\n",
        "    return change_points, n_frame_per_seg\n",
        "\n",
        "\n",
        "  def generate_ds(self):\n",
        "    for video_idx, video_filename in enumerate(self.video_list):\n",
        "      video_path = video_filename\n",
        "      if os.path.isdir(self.video_path):\n",
        "        video_path = os.path.join(self.video_path, video_filename)\n",
        "      video_basename = os.path.basename(video_path).split(\".\")[0]\n",
        "\n",
        "      if not os.path.exists(os.path.join(self.frame_root_path, video_basename)):\n",
        "        os.mkdir(os.path.join(self.frame_root_path, video_basename))\n",
        "\n",
        "      video_capture = cv2.VideoCapture(video_path)\n",
        "      fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "      n_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "      n_train_frames = int(n_frames / 15) +1\n",
        "      count_train = 0 \n",
        "      count_feat = 0\n",
        "      picks = []\n",
        "      video_feat = np.zeros(shape = (n_frames-n_train_frames,512))\n",
        "      video_feat_for_train = np.zeros(shape = (n_train_frames,512))\n",
        "\n",
        "      for frame_idx in range(n_frames-1):\n",
        "        success, frame = video_capture.read()\n",
        "        img_filename = \"{}.jpg\".format(str(frame_idx).zfill(5))\n",
        "        cv2.imwrite(os.path.join(self.frame_root_path, video_basename, img_filename), frame)\n",
        "        if success:\n",
        "          if frame_idx % 15 == 0:\n",
        "            picks.append(frame_idx)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = frame[None, ...]\n",
        "            feature = feature_extractor.predict(frame)\n",
        "            feature = feature.flatten()\n",
        "            video_feat_for_train[count_train] = feature\n",
        "            count_train += 1\n",
        "          else:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = frame[None, ...]\n",
        "            feature = feature_extractor.predict(frame)\n",
        "            feature = feature.flatten()\n",
        "            video_feat[count_feat] = feature\n",
        "            count_feat += 1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "      video_capture.release()      \n",
        "\n",
        "      change_points, n_frame_per_seg = self.get_change_point(video_feat, n_frames, fps)\n",
        "      \n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['features'] = list(video_feat_for_train)\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['picks'] = np.array(list(picks))\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['n_frames'] = n_frames\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['fps'] = fps\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['change_points'] = change_points\n",
        "      self.h5_file['video_{}'.format(video_idx+1)]['n_frame_per_seg'] = n_frame_per_seg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQmSwYUf1-2h"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    gen = Data_GeneratorNew('/content/drive/MyDrive/TVSUM/video', '/content/drive/MyDrive/TVSum.h5')\n",
        "    gen.generate_ds()\n",
        "    gen.h5_file.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "generate_dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}