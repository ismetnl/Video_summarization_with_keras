{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiDrWVxx8EWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e040ac8-c401-4dae-cc7d-d3cf85a39612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzskOTt3BTRL"
      },
      "source": [
        "#current model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_2SKow-O99ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XccOxW1np2ok"
      },
      "source": [
        "# Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKDiOb2qQNO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb516631-7f9f-474b-eda9-3b149b411f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 40.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 43.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 45.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 50.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 36.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ffmpeg moviepy"
      ],
      "metadata": {
        "id": "h8HnTK6k0Coq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsdxCCBG8Ebx"
      },
      "outputs": [],
      "source": [
        "!pip install keras-layer-normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2Gw2bn9MEzF"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc2-lQIz7rZo"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "import tensorflow_addons as tfa\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Flatten, Bidirectional, Dense, Permute, multiply,Dropout, LayerNormalization,GaussianNoise, GaussianDropout ,GlobalAveragePooling1D,BatchNormalization\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "import numpy as np\n",
        "import h5py\n",
        "import math\n",
        "from pandas import read_json\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWmlbgOedbIG"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.layers import Input, Dense, Flatten, Activation, Dropout, Bidirectional, Permute, multiply\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "#from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import moviepy.editor as mp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmbZuw_wlrw"
      },
      "source": [
        "# Set Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OejpysmMgUvB"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  DATASET_PATH =\"/content/drive/MyDrive/TVSum.h5\"\n",
        "  BATCH_SIZE = 1\n",
        "  EPOCHS = 120\n",
        "  MODEL_PATH = \"/content/drive/MyDrive/summe/models/summary_TVSum_model.hdf5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM52AZeGwfvQ"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVB9ig6dEd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940b8eac-c52d-44ea-9728-c5e762e618a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "# total videos 50. # train videos 40. # test videos 10.\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "def Load_dataset():\n",
        "  dataset = h5py.File(Config.DATASET_PATH, 'r')\n",
        "  num_videos = len(dataset.keys())\n",
        "  print(num_videos)\n",
        "\n",
        "  SPLIT = \"/content/drive/MyDrive/TVSum_splits.json\"\n",
        "  SPLIT_ID = 0\n",
        "  splits = read_json(SPLIT)\n",
        "  TEST = False\n",
        "  if not TEST:\n",
        "      assert SPLIT_ID < len(splits), \"split_id (got {}) exceeds {}\".format(SPLIT_ID, len(splits ))\n",
        "      train_keys = splits[\"train_keys\"][0]\n",
        "      test_keys = splits[\"test_keys\"][0]\n",
        "      print(\"# total videos {}. # train videos {}. # test videos {}.\".format(num_videos, len(train_keys), len(test_keys)))\n",
        "\n",
        "  return dataset, train_keys, test_keys\n",
        "\n",
        "dataset, train_keys, test_keys = Load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJJhOnZcKazD"
      },
      "outputs": [],
      "source": [
        "def Load_dataset_for_single():\n",
        "  dataset = h5py.File(Config.DATASET_PATH, 'r')\n",
        "  return dataset\n",
        "  \n",
        "dataset = Load_dataset_for_single()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEMeN_fcqB5n"
      },
      "source": [
        "#Auto tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaCtm6T-bjEJ"
      },
      "outputs": [],
      "source": [
        "def reg_wrapper(type, value):\n",
        "    if type == 'l2':\n",
        "        return regularizers.l2(value)\n",
        "    if type == 'l1':\n",
        "        return regularizers.l1(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3CtaAVXQFwp"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "  \n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "  model.add(LayerNormalization())\n",
        "  model.add(keras.layers.GaussianNoise(0.2))\n",
        "  model.add(keras.layers.GaussianDropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(units=128, return_sequences=True )))\n",
        "  model.add(keras.layers.GaussianNoise(0.2))\n",
        "  model.add(keras.layers.GaussianDropout(0.1))\n",
        "  model.add(LayerNormalization())\n",
        "  reg1 = reg_wrapper(hp.Choice('type', ['l1', 'l2', 'l1_l2']), hp.Choice('reg_value1', [0.01,0.001,0.1,0.005,0.05]))\n",
        "  reg2 = reg_wrapper(hp.Choice('type2', ['l1', 'l2', 'l1_l2']), hp.Choice('reg_value2', [0.01,0.001,0.1,0.005,0.05]))\n",
        "  model.add(Dense(hp.Int('hidden_size', 256, 1024, step=10, default=50),activation=\"relu\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=reg1))\n",
        "  model.add(Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.5)))\n",
        "  model.add(TimeDistributed(Dense(1,activation=\"relu\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=reg2)))\n",
        "\n",
        "  model.compile(loss='cosine_similarity', optimizer= tf.keras.optimizers.Nadam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')), metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vp7OtymUFCV"
      },
      "outputs": [],
      "source": [
        "def train_prepare(dataset, train_keys):\n",
        "  indices = np.arange(len(train_keys))\n",
        "  count = 0\n",
        "  np.random.shuffle(indices)\n",
        "  \n",
        "  data_seq = np.zeros((30,400,512))\n",
        "  for idx in indices:\n",
        "    key = train_keys[idx]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    seq_split = np.vsplit(seq,[400])  \n",
        "    if seq_split[1].shape[0] != 0 :\n",
        "      seq_split[1]= np.resize(seq_split[1],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "      data_seq[count] = seq_split[1]\n",
        "      count += 1\n",
        "      \n",
        "    else:\n",
        "      seq_split[0]= np.resize(seq_split[0],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "  \n",
        "  return data_seq\n",
        "\n",
        "train_set = train_prepare(dataset, train_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rU5yO8IPSXp"
      },
      "outputs": [],
      "source": [
        "tuner = kt.RandomSearch(model_builder,\n",
        "                     objective='accuracy',\n",
        "                     max_trials=5,project_name='hyperband_tuner4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ-bmVANQWJ0"
      },
      "outputs": [],
      "source": [
        "tuner.search(train_set, train_set, epochs=50)\n",
        "\n",
        "model=tuner.get_best_models(num_models=1)[0]\n",
        "model.fit(train_set,train_set, epochs=50)\n",
        "# Get the optimal hyperparameters\n",
        "#best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBL3zTRnBnCL"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/umodels/hyper_model.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "rFJgjpSzwHSG",
        "outputId": "4079e162-2d26-400a-ef9e-001f1e63425c"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-5747183b3ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not callable"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjDgJ1tYpZYA"
      },
      "source": [
        "# Train model(normal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MICNoHX0mIw4"
      },
      "outputs": [],
      "source": [
        "def get_model(train_set,reload_model=True):\n",
        "  \n",
        "  #callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n",
        "  model = Sequential()\n",
        "  \n",
        "  if reload_model:\n",
        "    if os.path.isfile(Config.MODEL_PATH):\n",
        "      model = load_model(Config.MODEL_PATH)\n",
        "      model.fit(train_set,train_set,batch_size=1, epochs=Config.EPOCHS, shuffle=False)\n",
        "      model.save(Config.MODEL_PATH)\n",
        "      return model\n",
        "  \n",
        "  \n",
        "  model.add(Bidirectional(LSTM(units=256, return_sequences=True,\n",
        "                          input_shape=(train_set.shape[1],train_set.shape[2] ))))\n",
        "  model.add(LayerNormalization())\n",
        "  model.add(keras.layers.GaussianNoise(0.2))\n",
        "  model.add(keras.layers.GaussianDropout(0.2))\n",
        "  model.add(Bidirectional(LSTM(units=128, return_sequences=False )))\n",
        "  model.add(keras.layers.GaussianNoise(0.2))\n",
        "  model.add(keras.layers.GaussianDropout(0.2))\n",
        "  model.add(LayerNormalization())\n",
        "  model.add(Dense(886,activation=\"relu\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=regularizers.l1_l2(0.005)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(512,activation=\"relu\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=regularizers.l1_l2(0.1)))\n",
        "  model.compile(loss='cosine_similarity', optimizer= tf.keras.optimizers.Nadam(), metrics=[\"accuracy\"])\n",
        "  model.fit(train_set,train_set,batch_size=Config.BATCH_SIZE, epochs=50, shuffle=False)\n",
        "  model.save(Config.MODEL_PATH)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_V_JSqHQxul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "f78900a2-13e3-43d5-a5ab-7b1bf249b8a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-5b9845043f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-5b9845043f1a>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(dataset, train_keys)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mdata_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-5d15a0e6dc31>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(train_set, reload_model)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlorotUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlorotUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine_similarity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNadam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       raise ValueError(\n\u001b[0;32m--> 121\u001b[0;31m           \u001b[0;34m'Please initialize `TimeDistributed` layer with a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m           f'`tf.keras.layers.Layer` instance. Received: {layer}')\n\u001b[1;32m    123\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please initialize `TimeDistributed` layer with a `tf.keras.layers.Layer` instance. Received: 1"
          ]
        }
      ],
      "source": [
        "def train_all(dataset, train_keys):\n",
        "  indices = np.arange(len(train_keys))\n",
        "  count = 0\n",
        "  seq_size = 0\n",
        "  np.random.shuffle(indices)\n",
        "  for idx in indices:\n",
        "    key = train_keys[idx]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    seq_size += int(seq.shape[0] / 400) + 1\n",
        "\n",
        "\n",
        "  data_seq = np.zeros((seq_size,400,512))\n",
        "  for idx in indices:\n",
        "    key = train_keys[idx]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    seq_split = np.vsplit(seq,[400])  \n",
        "    if seq_split[1].shape[0] != 0 :\n",
        "      seq_split[1]= np.resize(seq_split[1],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "      data_seq[count] = seq_split[1]\n",
        "      count += 1\n",
        "      \n",
        "    else:\n",
        "      seq_split[0]= np.resize(seq_split[0],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "  model = get_model(data_seq,False)\n",
        "  \n",
        "  return model\n",
        "\n",
        "model = train_all(dataset, train_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh-AubkzpgfN"
      },
      "source": [
        "#Train model with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI5IUT6i00Xa"
      },
      "outputs": [],
      "source": [
        "def attention_block(inputs, time_steps):\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Dense(time_steps, activation='softmax')(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
        "    return output_attention_mul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYV3ijIA0Gms"
      },
      "outputs": [],
      "source": [
        "def get_seq_model(train_set):\n",
        "  frame_features_input = keras.Input((400,512))\n",
        "  lstm_out = Bidirectional(LSTM(units=256,name=\"lstm1\", return_sequences=True, input_shape=(train_set.shape[1],train_set.shape[2]) ))(frame_features_input)\n",
        "  lstm_out = Bidirectional(LSTM(units=128, name=\"lstm2\", return_sequences=True ))(lstm_out)\n",
        "\n",
        "  lstm_out = GaussianNoise(0.2)(lstm_out)\n",
        "  lstm_out = GaussianDropout(0.1)(lstm_out)\n",
        "  lstm_out = LayerNormalization()(lstm_out)\n",
        "\n",
        "  print(lstm_out.shape)\n",
        "  attention_mul = attention_block(lstm_out, lstm_out.shape[1])\n",
        "  attention_mul = GlobalAveragePooling1D()(attention_mul)\n",
        "\n",
        "  x = Dense(1024,name=\"dense1\",activation=\"relu\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(attention_mul)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = TimeDistributed(Dense(1,activation=\"softmax\", kernel_initializer = tf.keras.initializers.GlorotUniform() ,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)))(x)\n",
        "  \n",
        "  model = Model(frame_features_input, x)\n",
        "  model.compile(loss='cosine_similarity', optimizer= tf.keras.optimizers.Nadam() , metrics=[\"accuracy\"])\n",
        "  model.fit(train_set,train_set,batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYeeoI-J1dQN"
      },
      "outputs": [],
      "source": [
        "def train_attention_model(dataset, train_keys):\n",
        "  indices = np.arange(len(train_keys))\n",
        "  count = 0\n",
        "  np.random.shuffle(indices)\n",
        "  \n",
        "  data_seq = np.zeros((30,400,512))\n",
        "  for idx in indices:\n",
        "    key = train_keys[idx]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    seq_split = np.vsplit(seq,[400])  \n",
        "    if seq_split[1].shape[0] != 0 :\n",
        "      seq_split[1]= np.resize(seq_split[1],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "      data_seq[count] = seq_split[1]\n",
        "      count += 1\n",
        "      \n",
        "    else:\n",
        "      seq_split[0]= np.resize(seq_split[0],(400,512))\n",
        "      data_seq[count] = seq_split[0]\n",
        "      count += 1\n",
        "  \n",
        "  model = get_seq_model(data_seq)\n",
        "  \n",
        "  return model\n",
        "\n",
        "model = train_attention_model(dataset,train_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-FOuHd13W8"
      },
      "source": [
        "# Vsum methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sf0v3x1_SK8"
      },
      "outputs": [],
      "source": [
        "def knapsack_dp(values,weights,n_items,capacity,return_all=False):\n",
        "    check_inputs(values,weights,n_items,capacity)\n",
        "\n",
        "    table = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "    keep = np.zeros((n_items+1,capacity+1),dtype=np.float32)\n",
        "\n",
        "    for i in range(1,n_items+1):\n",
        "        for w in range(0,capacity+1):\n",
        "            wi = weights[i-1] # weight of current item\n",
        "            vi = values[i-1] # value of current item\n",
        "            if (wi <= w) and (vi + table[i-1,w-wi] > table[i-1,w]):\n",
        "                table[i,w] = vi + table[i-1,w-wi]\n",
        "                keep[i,w] = 1\n",
        "            else:\n",
        "                table[i,w] = table[i-1,w]\n",
        "\n",
        "    picks = []\n",
        "    K = capacity\n",
        "\n",
        "    for i in range(n_items,0,-1):\n",
        "        if keep[i,K] == 1:\n",
        "            picks.append(i)\n",
        "            K -= weights[i-1]\n",
        "\n",
        "    picks.sort()\n",
        "    picks = [x-1 for x in picks] # change to 0-index\n",
        "\n",
        "    if return_all:\n",
        "        max_val = table[n_items,capacity]\n",
        "        return picks,max_val\n",
        "    return picks\n",
        "\n",
        "def check_inputs(values, weights, n_items, capacity):\n",
        "    # check variable type\n",
        "    assert(isinstance(values,list))\n",
        "    assert(isinstance(weights,list))\n",
        "    assert(isinstance(n_items,int))\n",
        "    assert(isinstance(capacity,int))\n",
        "    # check value type\n",
        "    assert(all(isinstance(val,int) or isinstance(val,float) for val in values))\n",
        "    assert(all(isinstance(val,int) for val in weights))\n",
        "    # check validity of value\n",
        "    assert(all(val >= 0 for val in weights))\n",
        "    assert(n_items > 0)\n",
        "    assert(capacity > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6ZZ1Jyl_dkL"
      },
      "outputs": [],
      "source": [
        "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.15, method='knapsack'):\n",
        "    \"\"\"\n",
        "        Generate keyshot-based video summary. i.e. a binary vector\n",
        "\n",
        "    Args:\n",
        "        ypred: predicted importance scores.\n",
        "        cps: change points, 2D matrix, each row contains a segment.\n",
        "        n_frames: original number of frames.\n",
        "        nfps: number of frames per segment.\n",
        "        positions: positions of subsampled frames in the original video.\n",
        "        proportion: length of video summary (compared to original video length).\n",
        "        method: defines how shots are selected, ['knapsack', 'rank'].\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    n_segs = cps.shape[0]\n",
        "\n",
        "    # Frame Score\n",
        "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
        "    if positions.dtype != int:\n",
        "        positions = positions.astype(np.int32)\n",
        "\n",
        "    if positions[-1] != n_frames:\n",
        "        positions = np.concatenate([positions, [n_frames]])\n",
        "\n",
        "    for idx in range(len(positions) - 1):\n",
        "        pos_cur, pos_next = positions[idx], positions[idx+1]\n",
        "\n",
        "        if idx >= len(ypred):\n",
        "            frame_scores[pos_cur:pos_next] = 0\n",
        "        else:\n",
        "            frame_scores[pos_cur:pos_next] = ypred[idx]\n",
        "\n",
        "    # Segment Score\n",
        "    seg_score = []\n",
        "    for seg_idx in range(n_segs):\n",
        "        pos_start, pos_end = int(cps[seg_idx, 0]), int(cps[seg_idx, 1]+1)\n",
        "        scores = frame_scores[pos_start: pos_end]\n",
        "        seg_score.append(float(scores.mean()))\n",
        "\n",
        "    limits = int(math.floor(n_frames * proportion))\n",
        "\n",
        "    if method == 'knapsack':\n",
        "        picks = knapsack_dp(seg_score, nfps, n_segs, limits)\n",
        "    elif method == 'rank':\n",
        "        order = np.argsort(seg_score)[::-1].tolist()\n",
        "        picks = []\n",
        "        total_len = 0\n",
        "\n",
        "        for idx in order:\n",
        "            if total_len + nfps[idx] < limits:\n",
        "                picks.append(idx)\n",
        "                total_len += nfps[idx]\n",
        "\n",
        "    else:\n",
        "        raise KeyError(\"Unknown method {}\".format(method))\n",
        "\n",
        "    summary = np.zeros((1), dtype=np.float32) # this element should be deleted\n",
        "    for seg_idx in range(n_segs):\n",
        "        nf = nfps[seg_idx]\n",
        "        if seg_idx in picks:\n",
        "            tmp = np.ones((nf), dtype=np.float32)\n",
        "        else:\n",
        "            tmp = np.zeros((nf), dtype=np.float32)\n",
        "\n",
        "        summary = np.concatenate((summary, tmp))\n",
        "\n",
        "    summary = np.delete(summary, 0) # delete the first element\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_video_summarization(index, size, test_features, key, datas, model):\n",
        "  \n",
        "  machine_summary = None\n",
        "\n",
        "  for idx in range(size):\n",
        "    print(key+idx)\n",
        "    temp = test_features[key+idx]\n",
        "    temp = temp[None,...]\n",
        "    cps = datas[index][idx]['change_points']\n",
        "    num_frames = datas[index][idx]['n_frames']\n",
        "    nfps = datas[index][idx]['n_frame_per_seg']\n",
        "    positions = datas[index][idx]['picks']\n",
        "    \n",
        "    predictions = model.predict(temp, verbose = 1)\n",
        "    probs = np.squeeze(predictions)\n",
        "    temp_machine_summary = generate_summary(probs, cps, num_frames, nfps, positions, proportion=0.20, method='knapsack')\n",
        "  \n",
        "    if machine_summary is not None:\n",
        "      np.concatenate((machine_summary, temp_machine_summary))\n",
        "    else:\n",
        "      machine_summary = temp_machine_summary\n",
        "\n",
        "\n",
        "  return machine_summary"
      ],
      "metadata": {
        "id": "1kG9g_RsubgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTR8A2R4uuKm"
      },
      "outputs": [],
      "source": [
        "def evaluate_summary(machine_summary, user_summary, eval_metric='avg'):\n",
        "    \"\"\"\n",
        "        Compare machine summary with user summary (Keyshot-based).\n",
        "\n",
        "    Args:\n",
        "        machine_summary: summary by machine\n",
        "        user_summary: summary by user(annotation)\n",
        "        eval_metric: {'avg', 'max'}\n",
        "            'avg' : average results of comparing multiple human summaries.\n",
        "            'max' : takes the maximum(best) out of multiple comparisons.\n",
        "    \"\"\"\n",
        "\n",
        "    machine_summary = machine_summary.astype(np.float32)\n",
        "    user_summary = user_summary.astype(np.float32)\n",
        "    n_users, n_frames = user_summary.shape\n",
        "\n",
        "    # binarization\n",
        "    machine_summary[machine_summary > 0] = 1\n",
        "    user_summary[user_summary > 0] = 1\n",
        "\n",
        "    if len(machine_summary) > n_frames:\n",
        "        machine_summary = machine_summary[:n_frames]\n",
        "    elif len(machine_summary) < n_frames:\n",
        "        zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
        "        machine_summary = np.concatenate([machine_summary, zero_padding])\n",
        "\n",
        "    f_scores = []\n",
        "    prec_arr = []\n",
        "    rec_arr = []\n",
        "\n",
        "    for user_idx in range(n_users):\n",
        "        gt_summary = user_summary[user_idx, :]\n",
        "        overlap_duration = (machine_summary * gt_summary).sum()\n",
        "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
        "        recall = overlap_duration / (gt_summary.sum() + 1e-8)\n",
        "        if precision == 0 and recall == 0:\n",
        "            f_score = 0.\n",
        "        else:\n",
        "            f_score = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "        f_scores.append(f_score)\n",
        "        prec_arr.append(precision)\n",
        "        rec_arr.append(recall)\n",
        "\n",
        "    if eval_metric == 'avg':\n",
        "        final_f_score = np.mean(f_scores)\n",
        "        final_prec = np.mean(prec_arr)\n",
        "        final_rec = np.mean(rec_arr)\n",
        "\n",
        "    elif eval_metric == 'max':\n",
        "        final_f_score = np.max(f_scores)\n",
        "        max_idx = np.argmax(f_scores)\n",
        "        final_prec = prec_arr[max_idx]\n",
        "        final_rec = rec_arr[max_idx]\n",
        "\n",
        "    return final_f_score, final_prec, final_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA9vKXzupqPv"
      },
      "source": [
        "#Test and Evalution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8JEYEMu7-15"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = load_model(Config.MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPw6DYxsrEkx"
      },
      "outputs": [],
      "source": [
        "def test_prepare(dataset,test_keys):\n",
        "  \n",
        "  # splits sequnence of frame features for test dataset\n",
        "  \n",
        "  indices = np.arange(len(test_keys))\n",
        "  np.random.shuffle(indices)\n",
        "  seq_idx = 0\n",
        "  temp = 0\n",
        "  datas = []\n",
        "  flag = []\n",
        "  seq_size = 0\n",
        "  video = []\n",
        "\n",
        "  for idx in indices:\n",
        "    key = test_keys[idx]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    seq_size += int(seq.shape[0] / 400) + 1\n",
        "\n",
        "  data_seq = np.zeros((seq_size,400,512))    \n",
        "  \n",
        "  for idx in indices:\n",
        "    key = test_keys[idx]\n",
        "    num_frames = dataset[key]['n_frames'][()]\n",
        "    seq = dataset[key]['features'][...]\n",
        "    cps = dataset[key]['change_points'][...]\n",
        "    nfps = dataset[key]['n_frame_per_seg'][...].tolist()\n",
        "    positions = dataset[key]['picks'][...]\n",
        "\n",
        "    seq_split = np.vsplit(seq,[400])  \n",
        "\n",
        "    while seq_split[-1].shape[0] > 400:\n",
        "      seq_split_temp = np.vsplit(seq_split[-1], [400])\n",
        "      seq_split = np.delete(seq_split,-1)\n",
        "      seq_split = np.concatenate((seq_split,seq_split_temp))\n",
        "\n",
        "    count = 0\n",
        "    video = []\n",
        "    temp = 0\n",
        "\n",
        "    if seq_split[1].shape[0] != 0:\n",
        "      \n",
        "      \n",
        "      len_cps = len(cps)\n",
        "      len_nfps = len(nfps)\n",
        "      len_positions = len(positions)\n",
        "\n",
        "      while int(seq_split[count].shape[0] / 400) != 0:\n",
        "\n",
        "        partian = 400/int(seq.shape[0])\n",
        "\n",
        "        current,next = temp,partian+temp\n",
        "        video_partian = {}\n",
        "        n_frames = int(num_frames * partian)\n",
        "        \n",
        "        cps_cur,cps_next = int(len_cps*current),int(len_cps*next)\n",
        "\n",
        "        change_points = cps[cps_cur:cps_next] \n",
        "        nfps_cur,nfp_next = int(len_nfps*current),int(len_nfps*next)\n",
        "        n_frame_per_seg = nfps[nfps_cur:nfp_next]\n",
        "        position_current,position_next = int(len_positions*current),int(len_positions*next)\n",
        "        position = positions[position_current:position_next]\n",
        "        temp += partian\n",
        "        \n",
        "        video_partian[\"n_frames\"] = n_frames\n",
        "        video_partian[\"change_points\"] = change_points\n",
        "        video_partian[\"n_frame_per_seg\"] = n_frame_per_seg\n",
        "        video_partian[\"picks\"] = position\n",
        "\n",
        "        video.append(video_partian)\n",
        "        \n",
        "        seq_split[count]= np.resize(seq_split[count],(400,512))\n",
        "        data_seq[seq_idx] = seq_split[count]\n",
        "        count += 1\n",
        "        seq_idx += 1\n",
        "\n",
        "\n",
        "\n",
        "      partian =seq_split[-1].shape[0]/int(seq.shape[0])\n",
        "      \n",
        "      current,next = temp,partian+temp\n",
        "      video_partian = {}\n",
        "      num_frames_partian = int(num_frames * partian)\n",
        "      \n",
        "      cps_cur,cps_next = int(len_cps*current),int(len_cps*next)\n",
        "      change_points = cps[cps_cur:]\n",
        "\n",
        "      nfps_cur,nfp_next = int(len_nfps*current),int(len_nfps*next)\n",
        "      n_frame_per_seg = nfps[nfps_cur:]\n",
        "\n",
        "      position_current,position_next = int(len_positions*current),int(len_positions*next)\n",
        "      position = positions[position_current:]\n",
        "\n",
        "\n",
        "      video_partian[\"n_frames\"] = num_frames_partian\n",
        "      video_partian[\"change_points\"] = change_points\n",
        "      video_partian[\"n_frame_per_seg\"] = n_frame_per_seg\n",
        "      video_partian[\"picks\"] = position\n",
        "\n",
        "      video.append(video_partian)\n",
        "      datas.append(video)\n",
        "\n",
        "      seq_split[-1]= np.resize(seq_split[-1],(400,512))\n",
        "      data_seq[count] = seq_split[-1]\n",
        "      count += 1\n",
        "      flag.append(1)\n",
        "\n",
        "    else:\n",
        "      seq_split[0]= np.resize(seq_split[0],(400,512))\n",
        "      data_seq[seq_idx] = seq_split[0]\n",
        "      count += 1\n",
        "      seq_idx += 1\n",
        "      flag.append(0)\n",
        "\n",
        "  return data_seq,flag,datas\n",
        "\n",
        "test_features,flag,datas = test_prepare(dataset,test_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPiWqxr8wqKH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def video_summarization(dataset,test_keys,flag,datas,user_summary_dataset):\n",
        "  \n",
        "  # generate video sum and final accuracy\n",
        "\n",
        "  index = 0\n",
        "  flag_count = 0\n",
        "  skip = False\n",
        "  fms = []\n",
        "  fcs = []\n",
        "  fprs = []\n",
        "  key_index = 0\n",
        "  summaries = []\n",
        "  for key_idx, key in enumerate(test_keys):\n",
        "    \n",
        "    if flag[flag_count] == 1:\n",
        "      size = len(datas[index])\n",
        "      machine_summary = concatenate_video_summarization(index,size,test_features, key_index, datas, model)\n",
        "      user_summary = user_summary_dataset[key]['user_summary'][...]\n",
        "      #fm = evaluate(machine_summary, user_summary)\n",
        "      fm, fp, fc = evaluate_summary(machine_summary, user_summary, \"max\")\n",
        "      fms.append(fm)\n",
        "      fcs.append(fc)\n",
        "      fprs.append(fp)\n",
        "      print(\"concatenate: \",machine_summary)\n",
        "      summaries.append(machine_summary)\n",
        "\n",
        "      flag_count += 1\n",
        "      key_index += size -1 \n",
        "      \n",
        "    else:\n",
        "      cps = dataset[key]['change_points'][...]\n",
        "      num_frames = dataset[key]['n_frames'][()]\n",
        "      nfps = dataset[key]['n_frame_per_seg'][...].tolist()\n",
        "      positions = dataset[key]['picks'][...]\n",
        "      temp = test_features[key_index]\n",
        "      temp = temp[None,...]\n",
        "\n",
        "      predictions = model.predict(temp, verbose = 1)\n",
        "      probs = np.squeeze(predictions)\n",
        "      machine_summary = generate_summary(probs, cps, num_frames, nfps, positions, proportion=0.20, method='knapsack')\n",
        "      print(\"single: \",machine_summary)\n",
        "      flag_count += 1\n",
        "      key_index += 1 \n",
        "      user_summary = user_summary_dataset[key]['user_summary'][...]\n",
        "      #fm = evaluate(machine_summary, user_summary)\n",
        "      fm,fp, fc = evaluate_summary(machine_summary, user_summary, \"avg\")\n",
        "      fms.append(fm)\n",
        "      fcs.append(fc)\n",
        "      fprs.append(fp)\n",
        "      summaries.append(machine_summary)\n",
        "\n",
        "  mean_fm = np.mean(fms)\n",
        "  mean_fc = np.mean(fcs)\n",
        "  mean_fp = np.mean(fprs)\n",
        "  print(\"Average F-Score {:.1%}\".format(mean_fm))\n",
        "  print(\"Average precision {:.1%}\".format(mean_fp))\n",
        "  print(\"Average Recall {:.1%}\".format(mean_fc))\n",
        "  return summaries\n",
        "\n",
        "user_summary_dataset = h5py.File(\"/content/drive/MyDrive/eccv16_dataset_tvsum_google_pool5.h5\",\"r\")\n",
        "summaries = video_summarization(dataset, test_keys, flag ,datas, user_summary_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Draw Confusion Matris"
      ],
      "metadata": {
        "id": "dqUEXErzngiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion_matrix(user_summary,machine_summary):\n",
        "  machine_summary = machine_summary.astype(np.float32)\n",
        "  user_summary = user_summary.astype(np.float32)\n",
        "  n_users, n_frames = user_summary.shape\n",
        "\n",
        "  # binarization\n",
        "  machine_summary[machine_summary > 0] = 1\n",
        "  user_summary[user_summary > 0] = 1\n",
        "\n",
        "  if len(machine_summary) > n_frames:\n",
        "      machine_summary = machine_summary[:n_frames]\n",
        "  elif len(machine_summary) < n_frames:\n",
        "      zero_padding = np.zeros((n_frames - len(machine_summary)))\n",
        "      machine_summary = np.concatenate([machine_summary, zero_padding])\n",
        "\n",
        "  gt_summary = user_summary[0, :]    \n",
        "  cm = confusion_matrix(gt_summary, machine_summary)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
        "  disp.plot()\n",
        "  plt.show()\n",
        "\n",
        "  return cm\n",
        "\n",
        "user_summary = user_summary_dataset[\"video_6\"]['user_summary'][...]\n",
        "cm = get_confusion_matrix(user_summary, summaries[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xrcZNM45GnvS",
        "outputId": "5f9a716f-6e1b-4a14-cc33-799f4725fda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "_1OWYK7fKMIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(random_state=0)"
      ],
      "metadata": {
        "id": "_QO-p_3dKMvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)\n",
        "clf = SVC(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "uTGdfwWZKb7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tek video için özet çalışması"
      ],
      "metadata": {
        "id": "atEyGbrzoDfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h842jT6wwS18"
      },
      "outputs": [],
      "source": [
        "def single_prepare(dataset):\n",
        "\n",
        "  # splits sequnence of frame features and other datas for single video (Ekstra olarak outputa length ekledim frame featurelarının boyutunu temsil ediyor)\n",
        "  \n",
        "  seq_idx = 0\n",
        "  temp = 0\n",
        "  datas = []\n",
        "  flag = []\n",
        "  seq_size = 0\n",
        "  video = []\n",
        "  key = \"video_1\"\n",
        "\n",
        "\n",
        "\n",
        "  seq = dataset[key]['features'][...]\n",
        "  length = seq.shape[0]\n",
        "  seq_size += int(seq.shape[0] / 400) + 1\n",
        "\n",
        "  data_seq = np.zeros((seq_size,400,512))    \n",
        "\n",
        "  num_frames = dataset[key]['n_frames'][()]\n",
        "  cps = dataset[key]['change_points'][...]\n",
        "  nfps = dataset[key]['n_frame_per_seg'][...].tolist()\n",
        "  positions = dataset[key]['picks'][...]\n",
        "  fps = dataset[key]['fps']\n",
        "  seq_split = np.vsplit(seq,[400])  \n",
        "  \n",
        "\n",
        "  while seq_split[-1].shape[0] > 400:\n",
        "    seq_split_temp = np.vsplit(seq_split[-1], [400])\n",
        "    seq_split = np.delete(seq_split,-1)\n",
        "    seq_split = np.concatenate((seq_split,seq_split_temp))\n",
        "\n",
        "  count = 0\n",
        "  video = []\n",
        "  temp = 0\n",
        "\n",
        "  if seq_split[1].shape[0] != 0:\n",
        "    \n",
        "    \n",
        "    len_cps = len(cps)\n",
        "    len_nfps = len(nfps)\n",
        "    len_positions = len(positions)\n",
        "\n",
        "    while int(seq_split[count].shape[0] / 400) != 0:\n",
        "\n",
        "      partian = 400/int(seq.shape[0])\n",
        "\n",
        "      current,next = temp,partian+temp\n",
        "      video_partian = {}\n",
        "      n_frames = int(num_frames * partian)\n",
        "      \n",
        "      cps_cur,cps_next = int(len_cps*current),int(len_cps*next)\n",
        "\n",
        "      change_points = cps[cps_cur:cps_next] \n",
        "      nfps_cur,nfp_next = int(len_nfps*current),int(len_nfps*next)\n",
        "      n_frame_per_seg = nfps[nfps_cur:nfp_next]\n",
        "      position_current,position_next = int(len_positions*current),int(len_positions*next)\n",
        "      position = positions[position_current:position_next]\n",
        "      temp += partian\n",
        "      \n",
        "      video_partian[\"n_frames\"] = n_frames\n",
        "      video_partian[\"change_points\"] = change_points\n",
        "      video_partian[\"n_frame_per_seg\"] = n_frame_per_seg\n",
        "      video_partian[\"picks\"] = position\n",
        "\n",
        "      video.append(video_partian)\n",
        "      \n",
        "      seq_split[count]= np.resize(seq_split[count],(400,512))\n",
        "      data_seq[seq_idx] = seq_split[count]\n",
        "      count += 1\n",
        "      seq_idx += 1\n",
        "\n",
        "\n",
        "\n",
        "    partian =seq_split[-1].shape[0]/int(seq.shape[0])\n",
        "    \n",
        "    current,next = temp,partian+temp\n",
        "    video_partian = {}\n",
        "    num_frames_partian = int(num_frames * partian)\n",
        "    \n",
        "    cps_cur,cps_next = int(len_cps*current),int(len_cps*next)\n",
        "    change_points = cps[cps_cur:]\n",
        "\n",
        "    nfps_cur,nfp_next = int(len_nfps*current),int(len_nfps*next)\n",
        "    n_frame_per_seg = nfps[nfps_cur:]\n",
        "\n",
        "    position_current,position_next = int(len_positions*current),int(len_positions*next)\n",
        "    position = positions[position_current:]\n",
        "\n",
        "\n",
        "    video_partian[\"n_frames\"] = num_frames_partian\n",
        "    video_partian[\"change_points\"] = change_points\n",
        "    video_partian[\"n_frame_per_seg\"] = n_frame_per_seg\n",
        "    video_partian[\"picks\"] = position\n",
        "\n",
        "    video.append(video_partian)\n",
        "    datas.append(video)\n",
        "    datas.append(fps)\n",
        "    seq_split[-1]= np.resize(seq_split[-1],(400,512))\n",
        "    data_seq[count] = seq_split[-1]\n",
        "    count += 1\n",
        "  else:\n",
        "      seq_split[0]= np.resize(seq_split[0],(400,512))\n",
        "      data_seq[seq_idx] = seq_split[0]\n",
        "      video_partian = {}\n",
        "      video_partian[\"n_frames\"] = num_frames\n",
        "      video_partian[\"change_points\"] = cps\n",
        "      video_partian[\"n_frame_per_seg\"] = nfps\n",
        "      video_partian[\"picks\"] = positions\n",
        "      video.append(video_partian)\n",
        "      datas.append(video)\n",
        "\n",
        "  return data_seq,datas,length\n",
        "\n",
        "data_seq,datas,length = single_prepare(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Y1MZQlpXCz",
        "outputId": "ae10f729-3884-43b8-a419-c439a7ed8110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ],
      "source": [
        "def single_video(data_seq, datas, model):\n",
        "\n",
        "\n",
        "  if length > 400:\n",
        "    size = len(datas[0])\n",
        "    machine_summary = concatenate_video_summarization(0, size,data_seq, 0, datas, model)\n",
        "\n",
        "  else:\n",
        "    cps = datas[0][0]['change_points']\n",
        "    num_frames = datas[0][0]['n_frames']\n",
        "    nfps = datas[0][0]['n_frame_per_seg']\n",
        "    positions = datas[0][0]['picks']\n",
        "\n",
        "    predictions = model.predict(data_seq, verbose = 1)\n",
        "    probs = np.squeeze(predictions)\n",
        "    machine_summary = generate_summary(probs, cps, num_frames, nfps, positions, proportion=0.20, method='knapsack')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return machine_summary\n",
        "\n",
        "machine_summary = single_video(data_seq, datas, model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sound_in_summary(video_dir, sound_dir, summary):\n",
        "  clips = []\n",
        "  end = -1\n",
        "  idx = 0\n",
        "  size = len(summary) \n",
        "  name_count = 0\n",
        "\n",
        "\n",
        "  while size > idx:\n",
        "    clip = []\n",
        "    \n",
        "    while size > idx and summary[idx] == 1.0 :\n",
        "      clip.append(idx)\n",
        "      idx += 1\n",
        "\n",
        "    if summary[idx-1] == 1.0:\n",
        "      clips.append(clip)\n",
        "      \n",
        "    idx += 1 \n",
        "\n",
        "  for clip in clips:\n",
        "    if len(clip) > 10:\n",
        "      video_capture = cv2.VideoCapture(video_dir)\n",
        "      fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "      sound_name = str(name_count).zfill(3) + '.wav'\n",
        "      sound_path = os.path.join(sound_dir, sound_name)\n",
        "      start = clip[0] / fps\n",
        "      end = clip[-1] / fps\n",
        "      print(start,end)\n",
        "      clip = mp.VideoFileClip(video_dir)\n",
        "      clip = clip.subclip(start, end)\n",
        "      clip.audio.write_audiofile(sound_path)\n",
        "      name_count += 1\n",
        "    else:\n",
        "      for frames_idx in clip:\n",
        "        summary[frames_idx] = 0.0\n",
        "\n",
        "  return summary"
      ],
      "metadata": {
        "id": "nxhA9bbulSAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = extract_sound_in_summary(\"/content/drive/MyDrive/video/denemeTest.mp4\", \"/content/drive/MyDrive/video\", machine_summary )"
      ],
      "metadata": {
        "id": "FNC_vESXrIca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7j9diwqqM8w"
      },
      "source": [
        "# Frameleri birleştirme işlemi ile video oluşturma\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyRvcH9Roygg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def frm2video(frm_dir, summary, vid_writer):\n",
        "    for idx, val in enumerate(summary):\n",
        "        \n",
        "        if val == 1.0:\n",
        "            frm_name = str(idx).zfill(5) + '.jpg'\n",
        "            frm_path = os.path.join(frm_dir, frm_name)\n",
        "            frm = cv2.imread(frm_path)\n",
        "            frm = cv2.resize(frm, (640, 480))\n",
        "            vid_writer.write(frm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "frm_dir = \"/content/drive/MyDrive/summe/frames/deneme2\"\n",
        "video_dir = \"/content/\"\n",
        "video_name = \"demo.mp4\"\n",
        "\n",
        "vid_writer = cv2.VideoWriter(\n",
        "        os.path.join(video_dir, video_name),\n",
        "        cv2.VideoWriter_fourcc(*'MP4V'),\n",
        "        30,\n",
        "        (640, 480),\n",
        "    )\n",
        "\n",
        "frm2video(frm_dir,machine_summary,vid_writer)\n",
        "vid_writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wTL2Mxdu2Z0V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nzskOTt3BTRL",
        "XccOxW1np2ok",
        "_dhnRNgap9kN",
        "SEMeN_fcqB5n",
        "YjDgJ1tYpZYA",
        "vh-AubkzpgfN"
      ],
      "name": "train_summary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}